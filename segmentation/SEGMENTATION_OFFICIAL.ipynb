{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASL Translator\n",
    "## This is the master preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan for classification\n",
    "\n",
    "    1. Train original images, output classification accuracy with original images\n",
    "    2. Train preprocessed images, output classification accuracy with preprocessed images\n",
    "    3. Compare accuracy between original images model and preprocessed images model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed pipeline\n",
    "\n",
    "- preprocess the images (this stuff)\n",
    "    - pick 2 or 3 different operation results\n",
    "- feed into Kira's mask algorithm\n",
    "    - removing background and keeping hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- normal images for training -> preprocessed images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import scipy.io\n",
    "from scipy import ndimage\n",
    "from skimage import feature\n",
    "from skimage import exposure\n",
    "from skimage import morphology\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk, ball\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3417: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "framesdir = \"../image-classification-tensorflow-master/dataset/V/\"\n",
    "fnames = glob.glob(framesdir + \"*.jpg\")\n",
    "fnames = [os.path.basename(name) for name in fnames]\n",
    "\n",
    "random_indeces = np.random.choice(len(fnames), 1, replace=False)\n",
    "chosen_fnames = np.take(fnames, random_indeces)\n",
    "    \n",
    "# original image\n",
    "original_image = imageio.imread(framesdir + chosen_fnames[0])\n",
    "\n",
    "# crop original image 5px from each side to remove border\n",
    "height, width, channels = original_image.shape\n",
    "original_image = original_image[5:width-5,5:height-5,:]\n",
    "\n",
    "# grayscale image\n",
    "gray_img = rgb2gray(original_image)\n",
    "\n",
    "# enhance contrast of the gray image\n",
    "high_contrast = exposure.equalize_hist(gray_img) * 255\n",
    "\n",
    "# reduce noise from enhanced image\n",
    "noiseless_img = median(high_contrast / 255, disk(3))\n",
    "\n",
    "# perform canny edge detector on reduced noise image\n",
    "edges_img = feature.canny(noiseless_img, sigma=1)\n",
    "\n",
    "######## COMBINED IMAGES WITH EDGES_IMG ########\n",
    "\n",
    "# overlay edges on original image\n",
    "inv_edges = np.where(edges_img == 1, 0, 1)\n",
    "combined_og = original_image * np.stack((inv_edges,inv_edges,inv_edges), axis=-1)   \n",
    "for yy in range(combined_og.shape[0]):\n",
    "    for xx in range(combined_og.shape[1]):\n",
    "        if np.array_equal(combined_og[yy,xx], np.zeros(3)):\n",
    "            combined_og[yy,xx] = np.array([255,255,0])\n",
    "\n",
    "# now, the output of part 1 of preprocessing (combined_og) will be available in PART1OUTPUT\n",
    "PART1OUTPUT = combined_og\n",
    "\n",
    "\n",
    "\n",
    "# show this output if you like\n",
    "# plt.imshow(PART1OUTPUT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########### IGNORE BELOW THIS LINE -> Kira will implement this after midterm update ###########\n",
    "\n",
    "\n",
    "# # Use threshold in gray image to find light and dark spots (separate thresholds may be used)\n",
    "# threshold = 0.25\n",
    "# light_spots = np.array((gray_img > 1- threshold).nonzero()).T\n",
    "# plt.plot(light_spots[:, 1], light_spots[:, 0], 'o', color='red', markersize=1)\n",
    "# dark_spots = np.array((gray_img < threshold).nonzero()).T\n",
    "# plt.plot(dark_spots[:, 1], dark_spots[:, 0], 'o', color='black', markersize=1)\n",
    "\n",
    "# bool_mask = np.zeros(gray_img.shape, dtype=np.bool)\n",
    "# bool_mask[tuple(light_spots.T)] = True\n",
    "# bool_mask[tuple(dark_spots.T)] = True\n",
    "# seed_mask, num_seeds = ndimage.label(bool_mask)\n",
    "\n",
    "# # Watershed mask to be used in the future to find the background and foreground\n",
    "# ws = morphology.watershed(noiseless_img, seed_mask)\n",
    "# # plt.imshow(ws)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ONLY USE THIS TO GENERATE THE IMAGES\n",
    "\n",
    "\n",
    "# framesdir = \"../image-classification-tensorflow-master/dataset/\"\n",
    "# savedirA = \"../image-classification-tensorflow-master/datasetA/\"\n",
    "# savedirB = \"../image-classification-tensorflow-master/datasetB/\"\n",
    "\n",
    "# letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "# for letter in letters:\n",
    "#     fnames = glob.glob(framesdir + letter + \"/\" + \"*.jpg\")\n",
    "#     fnames = [os.path.basename(name) for name in fnames]    \n",
    "#     i = 0\n",
    "#     for img_name in fnames:\n",
    "\n",
    "#         # original image\n",
    "#         original_image = imageio.imread(framesdir + letter + \"/\" + img_name)\n",
    "\n",
    "#         # crop original image 5px from each side to remove border\n",
    "#         height, width, channels = original_image.shape\n",
    "#         original_image = original_image[5:width-5,5:height-5,:]\n",
    "\n",
    "#         # grayscale image\n",
    "#         gray_img = rgb2gray(original_image)\n",
    "\n",
    "#         # enhance contrast of the gray image\n",
    "#         high_contrast = exposure.equalize_hist(gray_img) * 255\n",
    "\n",
    "#         # reduce noise from enhanced image\n",
    "#         noiseless_img = median(high_contrast / 255, disk(3))\n",
    "\n",
    "#         # perform canny edge detector on reduced noise image\n",
    "#         edges_img = feature.canny(noiseless_img, sigma=1)\n",
    "\n",
    "#         ######## COMBINED IMAGES WITH EDGES_IMG ########\n",
    "\n",
    "#         # overlay edges on original image\n",
    "#         inv_edges = np.where(edges_img == 1, 0, 1)\n",
    "#         combined_og = original_image * np.stack((inv_edges,inv_edges,inv_edges), axis=-1)   \n",
    "#         for yy in range(combined_og.shape[0]):\n",
    "#             for xx in range(combined_og.shape[1]):\n",
    "#                 if np.array_equal(combined_og[yy,xx], np.zeros(3)):\n",
    "#                     combined_og[yy,xx] = np.array([255,255,0])\n",
    "\n",
    "#         # now, the output of part 1 of preprocessing (combined_og) will be available in PART1OUTPUT\n",
    "#         PART1OUTPUT = combined_og\n",
    "        \n",
    "#         # save the image in the savedir\n",
    "#         imageio.imwrite(savedirA + \"normal_\" + img_name, original_image)\n",
    "#         imageio.imwrite(savedirB + \"processed_\" + img_name, PART1OUTPUT)\n",
    "        \n",
    "#         i += 1\n",
    "#         if i >= 50:\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
