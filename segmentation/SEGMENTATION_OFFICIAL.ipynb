{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASL Translator\n",
    "## This is the master preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan for classification\n",
    "\n",
    "    1. Train original images, output classification accuracy with original images\n",
    "    2. Train preprocessed images, output classification accuracy with preprocessed images\n",
    "    3. Compare accuracy between original images model and preprocessed images model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed pipeline\n",
    "\n",
    "- preprocess the images (this stuff)\n",
    "    - pick 2 or 3 different operation results\n",
    "- feed into Kira's mask algorithm\n",
    "    - removing background and keeping hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- normal images for training -> preprocessed images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import scipy.io\n",
    "from skimage import feature\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk, ball\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesdir = \"../image-classification-tensorflow-master/dataset/V/\"\n",
    "fnames = glob.glob(framesdir + \"*.jpg\")\n",
    "fnames = [os.path.basename(name) for name in fnames]\n",
    "\n",
    "random_indeces = np.random.choice(len(fnames), 1, replace=False)\n",
    "chosen_fnames = np.take(fnames, random_indeces)\n",
    "    \n",
    "# original image\n",
    "original_image = imageio.imread(framesdir + chosen_fnames[0])\n",
    "\n",
    "# crop original image 5px from each side to remove border\n",
    "height, width, channels = original_image.shape\n",
    "original_image = original_image[5:width-5,5:height-5,:]\n",
    "\n",
    "# grayscale image\n",
    "gray_img = rgb2gray(original_image)\n",
    "\n",
    "# enhance contrast of the gray image\n",
    "high_contrast = exposure.equalize_hist(gray_img) * 255\n",
    "\n",
    "# reduce noise from enhanced image\n",
    "noiseless_img = median(high_contrast / 255, disk(3))\n",
    "\n",
    "# perform canny edge detector on reduced noise image\n",
    "edges_img = feature.canny(noiseless_img, sigma=1)\n",
    "\n",
    "######## COMBINED IMAGES WITH EDGES_IMG ########\n",
    "\n",
    "# overlay edges on original image\n",
    "inv_edges = np.where(edges_img == 1, 0, 1)\n",
    "combined_og = original_image * np.stack((inv_edges,inv_edges,inv_edges), axis=-1)   \n",
    "for yy in range(combined_og.shape[0]):\n",
    "    for xx in range(combined_og.shape[1]):\n",
    "        if np.array_equal(combined_og[yy,xx], np.zeros(3)):\n",
    "            combined_og[yy,xx] = np.array([255,255,0])\n",
    "\n",
    "# now, the output of part 1 of preprocessing (combined_og) will be available in PART1OUTPUT\n",
    "PART1OUTPUT = combined_og\n",
    "# show this output if you like\n",
    "# plt.imshow(PART1OUTPUT)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
