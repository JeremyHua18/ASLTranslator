{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASL Translator\n",
    "## Run imports, then go to bottom for the official pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan for classification\n",
    "\n",
    "    1. Train original images, output classification accuracy with original images\n",
    "    2. Train preprocessed images, output classification accuracy with preprocessed images\n",
    "    3. Compare accuracy between original images model and preprocessed images model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed pipeline\n",
    "\n",
    "- preprocess the images (this stuff)\n",
    "    - pick 2 or 3 different operation results\n",
    "- feed into Kira's mask algorithm\n",
    "    - removing background and keeping hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- normal images for training -> preprocessed images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import scipy.io\n",
    "from skimage import feature\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk, ball\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesdir = \"../image-classification-tensorflow-master/dataset/V/\"\n",
    "fnames = glob.glob(framesdir + \"*.jpg\")\n",
    "fnames = [os.path.basename(name) for name in fnames]\n",
    "\n",
    "num_different_images = 3\n",
    "\n",
    "random_indeces = np.random.choice(len(fnames), num_different_images, replace=False)\n",
    "chosen_fnames = np.take(fnames, random_indeces)\n",
    "\n",
    "sigma1 = 0.1\n",
    "sigma2 = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(num_different_images,5,figsize=(7,7))\n",
    "fig.suptitle(\"Segmentation progression\", fontsize=14)\n",
    "\n",
    "for i in range(len(chosen_fnames)):\n",
    "    \n",
    "    # original image\n",
    "    original_image = imageio.imread(framesdir + chosen_fnames[i])\n",
    "    \n",
    "    # grayscale iamge\n",
    "    gray_img = rgb2gray(original_image)\n",
    "    \n",
    "    # perform canny edge detector on grayscale img using various sigma values\n",
    "    img_edges_sigma1 = feature.canny(gray_img, sigma=sigma1)\n",
    "    img_edges_sigma2 = feature.canny(gray_img, sigma=sigma2)\n",
    "    \n",
    "    # perform canny edge detector on the different rgb channels of smooth img\n",
    "    edges_r = feature.canny(original_image[:,:,0], sigma=1)\n",
    "    edges_g = feature.canny(original_image[:,:,1], sigma=1)\n",
    "    edges_b = feature.canny(original_image[:,:,2], sigma=1)\n",
    "    stacked = np.stack((edges_r,edges_g,edges_b), axis=-1)   \n",
    "    summed = np.sum(stacked, axis=2)\n",
    "    img_edges_rgb = np.where(summed >= 1, 1, 0)\n",
    "    \n",
    "    # display results\n",
    "    ax[i][0].imshow(original_image)\n",
    "    ax[i][0].set_title(\"Original\")\n",
    "    ax[i][1].imshow(img_edges_sigma1, cmap='gray')\n",
    "    ax[i][1].set_title(\"Sig = {}\".format(sigma1))\n",
    "    ax[i][2].imshow(img_edges_sigma2, cmap='gray')\n",
    "    ax[i][2].set_title(\"Sig = {}\".format(sigma2))\n",
    "    ax[i][3].imshow(img_edges_rgb, cmap='gray')\n",
    "    ax[i][3].set_title(\"Canny on R, G, B\")\n",
    "\n",
    "for j in range(5):\n",
    "    for i in range(len(chosen_fnames)):\n",
    "        ax[i][j].axis(\"off\")\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "framesdir = \"../image-classification-tensorflow-master/dataset/V/\"\n",
    "fnames = glob.glob(framesdir + \"*.jpg\")\n",
    "fnames = [os.path.basename(name) for name in fnames]\n",
    "\n",
    "num_different_images = 6\n",
    "\n",
    "random_indeces = np.random.choice(len(fnames), num_different_images, replace=False)\n",
    "chosen_fnames = np.take(fnames, random_indeces)\n",
    "\n",
    "sigma1 = 0.1\n",
    "sigma2 = 0.25\n",
    "sigma3 = 0.5\n",
    "sigma4 = 1\n",
    "sigma5 = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_different_images,ncols=9,figsize=(10,10))\n",
    "fig.suptitle(\"Segmentation progression\", fontsize=14)\n",
    "ax = axes.ravel()\n",
    "x = 0\n",
    "\n",
    "for i in range(len(chosen_fnames)):\n",
    "    \n",
    "    # original image\n",
    "    original_image = imageio.imread(framesdir + chosen_fnames[i])\n",
    "    \n",
    "    # grayscale image\n",
    "    gray_img = rgb2gray(original_image)\n",
    "    \n",
    "    # mean center the gray image (actually subtract 1/2 of the mean)\n",
    "    mean_centered_gray_img = gray_img - np.mean(gray_img)*0.5    \n",
    "    mean_centered_gray_img = np.where(mean_centered_gray_img < 0, 0, mean_centered_gray_img)\n",
    "    \n",
    "    # enhance contrast of the gray image\n",
    "    high_contrast = exposure.equalize_hist(gray_img) * 255\n",
    "    \n",
    "    # reduce noise from enhanced image\n",
    "    noiseless_img = median(high_contrast / 255, disk(3))\n",
    "    \n",
    "    # perform canny edge detector on reduced noise image\n",
    "    edges_img = feature.canny(noiseless_img, sigma=1)\n",
    "    \n",
    "    ######## COMBINED IMAGES WITH EDGES_IMG ########\n",
    "    \n",
    "    # overlay edges on original image\n",
    "    inv_edges = np.where(edges_img == 1, 0, 1)\n",
    "    combined_og = original_image * np.stack((inv_edges,inv_edges,inv_edges), axis=-1)   \n",
    "    for yy in range(combined_og.shape[0]):\n",
    "        for xx in range(combined_og.shape[1]):\n",
    "            if np.array_equal(combined_og[yy,xx], np.zeros(3)):\n",
    "                combined_og[yy,xx] = np.array([255,255,0])\n",
    "    \n",
    "    # overlay edges on gray image\n",
    "    combined_gray = gray_img * edges_img\n",
    "    combined_gray = np.where(combined_gray == 0, gray_img, 1)\n",
    "    \n",
    "    # overlay edges on mean image\n",
    "    combined_mean = mean_centered_gray_img * edges_img\n",
    "    combined_mean = np.where(combined_mean == 0, mean_centered_gray_img, 1)\n",
    "    \n",
    "    # overlay edges on enhanced contrast image\n",
    "    combined_hc = high_contrast / 255 * edges_img\n",
    "    combined_hc = np.where(combined_hc == 0, high_contrast / 255, 1)\n",
    "    \n",
    "    # overlay edges on reduced noise image\n",
    "    combined_noiseless = noiseless_img * edges_img\n",
    "    combined_noiseless = np.where(combined_noiseless == 0, noiseless_img / 255.0, 1)\n",
    "    \n",
    "    ax[x].imshow(combined_og)\n",
    "    ax[x].set_title(\"Comb. Og\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(gray_img, cmap='gray')\n",
    "    ax[x].set_title(\"Gray\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(combined_gray, cmap='gray')\n",
    "    ax[x].set_title(\"Comb. Gray\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(mean_centered_gray_img, cmap='gray')\n",
    "    ax[x].set_title(\"MC\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(combined_mean, cmap='gray')\n",
    "    ax[x].set_title(\"Comb. MC\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(high_contrast, cmap='gray')\n",
    "    ax[x].set_title(\"High Contrast\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(combined_hc, cmap='gray')\n",
    "    ax[x].set_title(\"Comb. HC\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(noiseless_img, vmin=0, vmax=255, cmap='gray')\n",
    "    ax[x].set_title(\"Reduced Noise\")\n",
    "    x += 1\n",
    "    \n",
    "    ax[x].imshow(combined_noiseless, cmap='gray')\n",
    "    ax[x].set_title(\"CombLessNoi\")\n",
    "    x += 1\n",
    "    \n",
    "for j in range(x):\n",
    "    ax[j].axis(\"off\")\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's output the comb. og image so that kira can use it as an input\n",
    "# let's see what the comb. og output looks like\n",
    "\n",
    "framesdir = \"../image-classification-tensorflow-master/dataset/V/\"\n",
    "fnames = glob.glob(framesdir + \"*.jpg\")\n",
    "fnames = [os.path.basename(name) for name in fnames]\n",
    "\n",
    "num_different_images = 6\n",
    "\n",
    "random_indeces = np.random.choice(len(fnames), num_different_images, replace=False)\n",
    "chosen_fnames = np.take(fnames, random_indeces)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3,ncols=4,figsize=(7,7))\n",
    "fig.suptitle(\"Segmentation progression\", fontsize=14)\n",
    "ax = axes.ravel()\n",
    "x = 0\n",
    "\n",
    "for i in range(len(chosen_fnames)):\n",
    "    \n",
    "    # original image\n",
    "    original_image = imageio.imread(framesdir + chosen_fnames[i])\n",
    "    \n",
    "    # crop original image 5px from each side to remove border\n",
    "    height, width, channels = original_image.shape\n",
    "    original_image = original_image[5:width-5,5:height-5,:]\n",
    "    \n",
    "    # grayscale image\n",
    "    gray_img = rgb2gray(original_image)\n",
    "    \n",
    "    # enhance contrast of the gray image\n",
    "    high_contrast = exposure.equalize_hist(gray_img) * 255\n",
    "    \n",
    "    # reduce noise from enhanced image\n",
    "    noiseless_img = median(high_contrast / 255, disk(3))\n",
    "    \n",
    "    # perform canny edge detector on reduced noise image\n",
    "    edges_img = feature.canny(noiseless_img, sigma=1)\n",
    "    \n",
    "    ######## COMBINED IMAGES WITH EDGES_IMG ########\n",
    "    \n",
    "    # overlay edges on original image\n",
    "    inv_edges = np.where(edges_img == 1, 0, 1)\n",
    "    combined_og = original_image * np.stack((inv_edges,inv_edges,inv_edges), axis=-1)   \n",
    "    for yy in range(combined_og.shape[0]):\n",
    "        for xx in range(combined_og.shape[1]):\n",
    "            if np.array_equal(combined_og[yy,xx], np.zeros(3)):\n",
    "                combined_og[yy,xx] = np.array([255,255,0])\n",
    "    \n",
    "    # show the results\n",
    "    ax[x].imshow(original_image)\n",
    "    x += 1\n",
    "    ax[x].imshow(combined_og)\n",
    "    x += 1\n",
    "    \n",
    "for j in range(x):\n",
    "    ax[j].axis(\"off\")\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will be where the official pipeline starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesdir = \"../image-classification-tensorflow-master/dataset/V/\"\n",
    "fnames = glob.glob(framesdir + \"*.jpg\")\n",
    "fnames = [os.path.basename(name) for name in fnames]\n",
    "\n",
    "random_indeces = np.random.choice(len(fnames), 1, replace=False)\n",
    "chosen_fnames = np.take(fnames, random_indeces)\n",
    "    \n",
    "# original image\n",
    "original_image = imageio.imread(framesdir + chosen_fnames[0])\n",
    "\n",
    "# crop original image 5px from each side to remove border\n",
    "height, width, channels = original_image.shape\n",
    "original_image = original_image[5:width-5,5:height-5,:]\n",
    "\n",
    "# grayscale image\n",
    "gray_img = rgb2gray(original_image)\n",
    "\n",
    "# enhance contrast of the gray image\n",
    "high_contrast = exposure.equalize_hist(gray_img) * 255\n",
    "\n",
    "# reduce noise from enhanced image\n",
    "noiseless_img = median(high_contrast / 255, disk(3))\n",
    "\n",
    "# perform canny edge detector on reduced noise image\n",
    "edges_img = feature.canny(noiseless_img, sigma=1)\n",
    "\n",
    "######## COMBINED IMAGES WITH EDGES_IMG ########\n",
    "\n",
    "# overlay edges on original image\n",
    "inv_edges = np.where(edges_img == 1, 0, 1)\n",
    "combined_og = original_image * np.stack((inv_edges,inv_edges,inv_edges), axis=-1)   \n",
    "for yy in range(combined_og.shape[0]):\n",
    "    for xx in range(combined_og.shape[1]):\n",
    "        if np.array_equal(combined_og[yy,xx], np.zeros(3)):\n",
    "            combined_og[yy,xx] = np.array([255,255,0])\n",
    "\n",
    "# now, the output of part 1 of preprocessing (combined_og) will be available in PART1OUTPUT\n",
    "PART1OUTPUT = combined_og\n",
    "# show this output if you like\n",
    "# plt.imshow(PART1OUTPUT)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
